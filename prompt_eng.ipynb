{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "027be427-411d-478c-9f22-6c2b95305abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from dotenv import load_dotenv\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4274cc50-d8fa-4a82-badc-fa6d0155cc80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(\"2.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e0e242-341d-425e-aa30-c29f792e57cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9b02951-d7f4-412d-a47c-bc284b00cbfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user_prompt = \"tell me a joke about datascientist\"\n",
    "# system_prompt = \"you are very careful assistant that cantell funny jokes, but the long one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1e7c6c10-8863-4871-ad72-9085e113c06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"tell me a joke about datascientist\"\n",
    "system_prompt = \"you are very careful assistant that cantell funny jokes, but the very very short one\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea01a41d-fe01-456c-b25b-9c17bb4c561b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BRjDoilXWKdhQiqU3hyPkHeEQRjrK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Why do data scientists love nature? \\n\\nBecause it has too many \"trees\"!', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1745948388, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_0392822090', usage=CompletionUsage(completion_tokens=17, prompt_tokens=37, total_tokens=54, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n",
      "<class 'openai.types.chat.chat_completion.ChatCompletion'>\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"user\", \"content\":user_prompt},\n",
    "        {\"role\":\"assistant\", \"content\":system_prompt}\n",
    "    ]\n",
    ")\n",
    "print(response)\n",
    "print(type(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3cfe7bd-21e0-499a-b37b-bf3272b5f156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sky is a vast expanse that surrounds the Earth, appearing in various colors and patterns depending on the time of day and weather conditions. During the day, it often displays shades of blue, while at sunrise and sunset, it can transform into vibrant hues of orange, pink, and purple. At night, the sky reveals stars, planets, and sometimes the moon, creating a beautiful tapestry that has fascinated humanity for centuries. What aspect of the sky are you interested in?\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1ccb0908-2340-4265-9ae1-7af46f20b6ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BRjUzpWq6irT8JthwonBncuhTfVOL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Negative', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1745949453, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_dbaca60df0', usage=CompletionUsage(completion_tokens=2, prompt_tokens=63, total_tokens=65, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "#we want to do few shot prompting \n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"you are a sentiment classifier. classifiy statements to Positive or Negative \"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\" This is awesome // Positive,\n",
    "        This is bad!// Negative,\n",
    "        Wow It is wonderful // Positive,\n",
    "        what a shame!// Negative,\n",
    "       what a stubborn boy!//\"\"\"}\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c3475a6e-cb38-47cc-896d-121c7767a1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cfc5b2a6-5a91-4f27-8401-77b7f0834797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BRjeoWynvZEF95QczpQMziCCKgxJB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='1. This is lovely waiting 3 hours for such movie - sarcasm\\n2. The file touched my heart and made me cry - genuine\\n3. This movie was the best wasting of my time ever - sarcasm', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1745950062, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_129a36352a', usage=CompletionUsage(completion_tokens=46, prompt_tokens=68, total_tokens=114, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "# now we look for am example of sarcasm that is contextual and traicky and need to use few shot prompting for that\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"you are a sentiment classifier. classifiy statements to sarcasm or genuine.\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\" this is lovely waiting 3 hours for such movie// sarcasm\n",
    "        the file touched my heart and made me cry//genuine\n",
    "        this  movie was the best wasting of my time ever//\n",
    "        \"\"\"}\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "16b80f9f-1180-4bdb-9b0d-822d8abe1f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sarcasm\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a64f7424-ec36-4a2c-8210-6d3580561ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletion(id='chatcmpl-BRjhQvc6yQBJLZx8KqIr9dGNY12z2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='sarcasm', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None, annotations=[]))], created=1745950224, model='gpt-4o-mini-2024-07-18', object='chat.completion', service_tier='default', system_fingerprint='fp_0392822090', usage=CompletionUsage(completion_tokens=4, prompt_tokens=82, total_tokens=86, completion_tokens_details=CompletionTokensDetails(accepted_prediction_tokens=0, audio_tokens=0, reasoning_tokens=0, rejected_prediction_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=0, cached_tokens=0)))\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"system\", \"content\":\"you are a sentiment classifier. classifiy statements to sarcasm or genuine.only state 'sarcasm' or 'genuine', no explanation\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\" this is lovely waiting 3 hours for such movie// sarcasm\n",
    "        the file touched my heart and made me cry//genuine\n",
    "        this  movie was the best wasting of my time ever//\n",
    "        \"\"\"}\n",
    "    ]\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8f6e5758-f198-4f70-9378-ea142de0d0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place: Champalimaud Centre for the Unknown, Lisbon\n"
     ]
    }
   ],
   "source": [
    "#extract the name of places in the following text\n",
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are helpful assistant that can generate response in specific format\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"extract the name of places in the following text:\n",
    "        desired format:\n",
    "        place: <comma-separated-list-of-places>\n",
    "        input:Although these developments are encouraging to researchers, much is still a mystery. \"We often have a black box between the brain and the effect we see in the \n",
    "        periphery,\" says Henrique Veiga-Fernandes, a neuroimmunologist at the Champalimaud Centre for the Unknown in Lisbon. \"If we want to use it in the therapeutic context, \n",
    "        we actually need to understand the mechanism.\"\n",
    "         \"\"\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "83e70982-f8e3-4583-b361-e9967f59377b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place: USA, California, San Francisco\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model = \"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are helpful assistant that can generate response in specific format\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"extract the name of places in the following text:\n",
    "        desired format:\n",
    "        place: <comma-separated-list-of-places>\n",
    "        input: we went USA California in sanfrancisco for a goodbye party\n",
    "         \"\"\"\n",
    "        }\n",
    "    ],\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "32669b7f-3b3c-4f44-aa90-0365a355665a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Author-contribution statements in research papers should explicitly disclose the use of AI technologies like ChatGPT in manuscript preparation and analysis to ensure transparency and allow for critical evaluation by editors and reviewers. Additionally, scientific journals are encouraged to be open about their use of large language models when managing submitted manuscripts.'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are a summariser assistant.please explain the text in exactly 3 sentences\"},\n",
    "        {\"role\":\"user\", \"content\":\"\"\"Author-contribution statements and acknowledgements in research papers should state clearly and specifically whether, and to what extent, the authors used AI technologies such as ChatGPT in the preparation of their manuscript and analysis. They should also indicate which LLMs were used. This will alert editors and reviewers to scrutinize manuscripts more carefully for potential biases, inaccuracies and improper source crediting. Likewise, scientific journals should be transparent about their use of LLMs, for example when selecting submitted manuscripts.\n",
    "Mention the large language model based product mentioned in the paragraph above:summarise in exactly 2 sentences\"\"\"\n",
    "        }\n",
    "    ]\n",
    "    \n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "36471ffa-074a-4a66-bb93-8578224a33e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mice.'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets fo for question answering\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\",\"content\":\"you are a question answering assistant, keep the answer short and concise. Respons 'UNSURE about answer' if not sure about the answer\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. \\\n",
    "        Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent \\\n",
    "        organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\n",
    "        Question: What was OKT3 originally sourced from?\n",
    "        Answer: \"\"\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd11dc2-bc8a-4f80-acf2-10945f0d9209",
   "metadata": {},
   "outputs": [],
   "source": [
    "#when we put Answer we only get the final abswer.if not we get full response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1d943dc5-8738-4b0d-ab89-da6e877f3c74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'OKT3 was originally sourced from mice.'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now lets fo for question answering\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\",\"content\":\"you are a question answering assistant, keep the answer short and concise. Respons 'UNSURE about answer' if not sure about the answer\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"Teplizumab traces its roots to a New Jersey drug company called Ortho Pharmaceutical. There, scientists generated an early version of the antibody, dubbed OKT3. \\\n",
    "        Originally sourced from mice, the molecule was able to bind to the surface of T cells and limit their cell-killing potential. In 1986, it was approved to help prevent \\\n",
    "        organ rejection after kidney transplants, making it the first therapeutic antibody allowed for human use.\\\n",
    "        Question: What was OKT3 originally sourced from?\n",
    "        \"\"\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "f62d9ceb-6721-4e5f-8b9a-08cf07cc8de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sentiment of \"this food tastes ok\" can be classified as neutral.'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets gor for text classifciation\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are classifier assistant.please classify the text neutral, positive, negative\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "         \"\"\"\n",
    "         this food is okay!// sentiment:neutral,\n",
    "         this food tastes ok//sentiment:}\n",
    "         \"\"\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "77754a1b-794d-4409-a09f-ceee9355186b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"```sql\\nSELECT s.StudentId, s.StudentName\\nFROM students s\\nJOIN departments d ON s.DepartmentId = d.DepartmentId\\nWHERE d.DepartmentName = 'Computer Science';\\n```\""
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now it is turn to code generation\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are code generator assistant.please generate MYSQL query.No text explanation.\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"\n",
    "        Table departments, columns = [DepartmentId, DepartmentName]\n",
    "        Table students, columns = [DepartmentId, StudentId, StudentName]\n",
    "        Create a MySQL query for all students in the Computer Science Department\n",
    "        \"\"\"}\n",
    "    ]\n",
    ")\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "7c3d0d95-0359-4f7d-be6a-162d0424f629",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```sql\n",
      "SELECT s.StudentId, s.StudentName\n",
      "FROM students s\n",
      "JOIN departments d ON s.DepartmentId = d.DepartmentId\n",
      "WHERE d.DepartmentName = 'Computer Science';\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "#axtually we dont want raw strings with new line characters, but we want the queries line by line like when we were writing in sql editor\n",
    "#use print to have that\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are code generator assistant.please generate MYSQL query.No text explanation.\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"\n",
    "        Table departments, columns = [DepartmentId, DepartmentName]\n",
    "        Table students, columns = [DepartmentId, StudentId, StudentName]\n",
    "        Create a MySQL query for all students in the Computer Science Department\n",
    "        \"\"\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab06c637-3d7b-4d6e-baee-026184e68e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now time for asvanced and confusing jobs for llm which is reasoninig. the moset challenging area for language models is handling the task that nedd reasoning. like math problems\n",
    "#for this we need more advanced prompt enginnering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "42a62278-f61e-477c-b305-76c9fd293448",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_403/2447690252.py:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "  {\"role\":\"assistant\", \"content\":\"you are math expert.always show step by step reasoning before giving the final answer.use clear logic and without explanation when solvng problems.\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average speed is calculated by dividing the total distance traveled by the total time taken.\n",
      "\n",
      "1. Total distance = 120 km\n",
      "2. Total time = 2 hours\n",
      "\n",
      "Average speed = Total distance / Total time  \n",
      "Average speed = 120 km / 2 hours  \n",
      "Average speed = 60 km/h\n",
      "\n",
      "Final answer: 60 km/h\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are math expert.always show step by step reasoning before giving the final answer.use clear logic and without explanation when solvng problems.\\\n",
    "        no LaTex or special formatting like \\[ or \\text{}\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "         \"A train travels 120 km in 2 hours.what is the average speed in km/h?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "7d799d16-aab6-436f-89ef-56d64fdb692f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_403/1761479854.py:5: SyntaxWarning: invalid escape sequence '\\['\n",
      "  {\"role\":\"assistant\", \"content\":\"you are a math tutor. always show step by step reasoning ehwn giving the answer.use clear logic with explanation\\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break this down step by step.\n",
      "\n",
      "1. The boy initially had 5 oranges.\n",
      "2. Out of these 5 oranges, he gave 2 to his sister. So, to find out how many oranges he had left after giving some to his sister, we subtract the number he gave away:\n",
      "\n",
      "   5 oranges (initial) - 2 oranges (given to sister) = 3 oranges left.\n",
      "\n",
      "3. Now, he picks 24 more oranges from the orange tree. To find out the total number of oranges he has now, we add the 24 oranges he picked to the 3 oranges he has left:\n",
      "\n",
      "   3 oranges (remaining) + 24 oranges (picked) = 27 oranges in total.\n",
      "\n",
      "So, the boy has 27 oranges in total.\n"
     ]
    }
   ],
   "source": [
    "#now we want to change the prompt a little bit to see if the result changes or not\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are a math tutor. always show step by step reasoning when giving the answer.use clear logic with explanation\\\n",
    "        no LaTex or special formatting like \\[ or \\] or \\text{}\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"\"\"\n",
    "        A boy has picked 24 oranges from an orange tree, before he hade 5 oranges which two of them was given to her sister now on the whole how many oranges the boy has?\n",
    "        \"\"\"}\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "5a19048e-572d-45ba-a485-a8608dde9f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The children began to farduddle with excitement when they saw the ice cream truck approaching.\n"
     ]
    }
   ],
   "source": [
    "#while language models are good at zero shot prompting still they fall short on more complex task. fewshot prompting can better instruct the modl and steer it to have better performance\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are assistant the provides example for new words that defined in the prompt\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"A 'whatpu' is a small, furry animal native to Tanzania. An example of a sentence that uses the word whatpu is:\"\n",
    "        \"We were traveling in Africa and we saw these very cute whatpus.\"\n",
    "        \"To do a 'farduddle' means to jump up and down really fast. An example of a sentence that uses the word farduddle is:\"}\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77be18d5-a1c3-4f7d-92d5-7f0004aef0f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "428577be-7f03-4a3e-baf5-76404161e58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Last night, I prepared a warm bowl of baghale ghatogh, combining fragrant baghaleh with eggs and fresh herbs, which filled our home with a delightful aroma.\"\n"
     ]
    }
   ],
   "source": [
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are assistant the provides example for new words that defined in the prompt\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"A food called 'baghale ghatogh' is a delicious food from Northen of Iran which contains baghaleh and egg with some veggies.Example of a sentence that uses the word baghaleh ghatogh is:\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c794cf7c-ecf8-4009-85e6-4d5d3eaa44d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitations of few shot prompting\n",
    "#limitation of few shot prompting\n",
    "\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are assistant the provides example for new words that defined in the prompt\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"A food called 'baghale ghatogh' is a delicious food from Northen of Iran which contains baghaleh and egg with some veggies.Example of a sentence that uses the word baghaleh ghatogh is:\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7121ac8a-8a52-4261-9e74-2194691043f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FALSE\n"
     ]
    }
   ],
   "source": [
    "#now we are going to show that in reasoning task even few shot prompting can not solve the problem correctly\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"The odd numbers in this group add up to an even number: 2, 3, 5, 7, 8, 4, 10\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb0e81be-2e1d-4db3-8f8e-c83255a4d994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify the odd numbers in the group: 3, 5, 7.\n",
      "\n",
      "Step 2: Add the odd numbers:  \n",
      "3 + 5 = 8  \n",
      "8 + 7 = 15\n",
      "\n",
      "Step 3: Check if the sum (15) is even or odd:  \n",
      "15 is odd.\n",
      "\n",
      "Conclusion: The statement is FALSE.\n"
     ]
    }
   ],
   "source": [
    "#now we are going to show that in reasoning task even few shot prompting can not solve the problem correctly\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.show step by step reasoning when giving the answer.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"The odd numbers in this group add up to an even number: 2, 3, 5, 7, 8, 4, 10\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fa7ceaa2-12b1-4a08-b0bc-933468dac8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify the odd numbers in the group: 17, 9, 13.  \n",
      "Step 2: Add the odd numbers:  \n",
      "17 + 9 + 13 = 39.  \n",
      "Step 3: Determine if 39 is even or odd: 39 is odd.  \n",
      "\n",
      "Answer: FALSE.\n"
     ]
    }
   ],
   "source": [
    "#now we are going to show that in reasoning task even few shot prompting can not solve the problem correctly\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.show step by step reasoning when giving the answer.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"The odd numbers in this group add up to an even number: 17,  9, 10, 12, 13, 4, 2.\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "02f873c4-c2f2-43fa-902e-e893d483e9b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Identify odd numbers from the list: 17, 9, 13.  \n",
      "Step 2: Calculate the sum of these odd numbers:  \n",
      "\\( 17 + 9 + 13 = 39 \\)  \n",
      "Step 3: Divide the sum by 2:  \n",
      "\\( 39 / 2 = 19.5 \\)  \n",
      "Step 4: Check if the result is an integer:  \n",
      "19.5 is not an integer.  \n",
      "\n",
      "Final answer: FALSE.\n"
     ]
    }
   ],
   "source": [
    "#now we are going to show that in reasoning task even few shot prompting can not solve the problem correctly\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.show step by step reasoning when giving the answer.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "        \"calculate sum of odd number divided by 2 is integer number: 17,  9, 10, 12, 13, 4, 2.\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b638b88-f122-40d8-9265-1da043c51189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's calculate the total number of apples in the cafeteria step by step.\n",
      "\n",
      "1. Starting number of apples = 23\n",
      "2. Apples used for lunch = 3\n",
      "3. Apples bought = 6\n",
      "\n",
      "Now, we subtract the apples used from the initial count:\n",
      "23 - 3 = 20 (apples remaining after lunch)\n",
      "\n",
      "Next, we add the apples bought:\n",
      "20 + 6 = 26 (total apples in the cafeteria now)\n",
      "\n",
      "A: The answer is 26.\n"
     ]
    }
   ],
   "source": [
    "#it seems the llm can solve the tas successfully. but in the case of more complex task that zero shot prompting and few shot prompting can not help getting expected out put\n",
    "# we go through Chain of Thought (COT)\n",
    "\n",
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.show step by step reasoning when giving the answer.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "            \"Q: Roger has 5 tennis balls. he buys 2 more can s of tennis balls. each can has 3 tennis balls.How many tennis balls he has on the whole?\\\n",
    "            A: the answer is 11\"\n",
    "            \"Q:The caffe teria has 23 apples. if they used 3 for lunch and bought 6 more, how many apples do they have?\\\n",
    "            A:\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0962139-fb70-411e-9ce4-6472ab989363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cafeteria started with 23 apples. They used 3 apples, so they have 23 - 3 = 20 apples left. Then they bought 6 more apples, so they have 20 + 6 = 26 apples. \n",
      "\n",
      "Therefore, the answer is 26.\n"
     ]
    }
   ],
   "source": [
    "response= openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are expert in math.show step by step reasoning when giving the answer.that can verify the answer of questions as TRUE or FALSE. no explanation\"},\n",
    "        \n",
    "        {\"role\":\"user\", \"content\":\n",
    "            \"Q: Roger has 5 tennis balls. he buys 2 more can s of tennis balls. each can has 3 tennis balls.How many tennis balls he has on the whole?\\\n",
    "            A: Roger started with 5. 2 cans of 3 tennis balls have 2*3 = 6 tennis balls,so the answer is 6 +5 = 11\"\n",
    "            \"Q:The caffe teria has 23 apples. if they used 3 for lunch and bought 6 more, how many apples do they have?\\\n",
    "            A:\"\n",
    "        }\n",
    "\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec4c2210-b39b-4039-b987-149fcd7b8798",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "/tmp/ipykernel_1819/3205919668.py:5: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  {\"role\":\"assistant\", \"content\":\"you are math expert.show step by step reasoning when giving an answer.use clear logic.explain each step when solving the question.answer without special format like \\] or \\text{}\"},\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's break down the problem step by step.\n",
      "\n",
      "1. **Starting Quantity**: Mary starts with 30 apples.\n",
      "\n",
      "2. **Boxes of Apples**: Mary buys 2 packs of apples. Each pack has 5 apples. \n",
      "   - Calculate the total number of apples in the packs:\n",
      "     2 packs Ã— 5 apples/pack = 10 apples.\n",
      "\n",
      "3. **Total After Purchase**: Now, add the apples she bought to her starting amount:\n",
      "   - 30 apples (original) + 10 apples (bought) = 40 apples.\n",
      "\n",
      "4. **Giving Away Apples**: Mary gives 5 apples to her mom.\n",
      "   - Subtract the 5 apples from the total:\n",
      "   - 40 apples - 5 apples = 35 apples.\n",
      "\n",
      "5. **Final Count**: Mary has 35 apples after all transactions.\n",
      "\n",
      "So, the final answer is that Mary has 35 apples.\n"
     ]
    }
   ],
   "source": [
    "#we have also somthing called zero shot/few shot COT prompting\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are math expert.show step by step reasoning when giving an answer.use clear logic.explain each step when solving the question.answer without special format like \\] or \\text{}\"},\n",
    "         {\"role\":\"user\", \"content\":\n",
    "          \"Q:Roger has 12 coins. He bought 2 boxes of coins each box has 4 coins.He gave 3 coins to his sister.how many coins does he have on the whole? \\\n",
    "          A: Roger started with 12 coins. 2 boxes of 4 coins is 8 coins.then he gave 3 coins so 8 -3 = 5, on the whole he has 12 + 5=17 coins\\\n",
    "          Q:Mary has 30 apples , she bough 2 pack of apples each with 5 apples , she decided to give 5 apples to her mom how many apples she has?\"}\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "94b71568-f80a-49d6-af9e-83fbdaaba966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "<>:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "/tmp/ipykernel_1819/1323328142.py:6: SyntaxWarning: invalid escape sequence '\\]'\n",
      "  {\"role\":\"assistant\", \"content\":\"you are math expert. show step by step reasoning when giving the answer. use clear logic.dont explain each step when sollving each step.dont use special formatting like \\text{} or \\]\"},\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1: Calculate the total number of oranges Roger initially has.  \n",
      "Roger has 2 packs of oranges, each containing 4 oranges.  \n",
      "Total oranges = 2 * 4 = 8 oranges.\n",
      "\n",
      "Step 2: Determine how many oranges Roger has after giving away 3 oranges.  \n",
      "Oranges after giving away = 8 - 3 = 5 oranges.\n",
      "\n",
      "Step 3: Calculate the total number of apples Roger receives.  \n",
      "His friend gives him 3 packs of apples, each containing 3 apples.  \n",
      "Total apples = 3 * 3 = 9 apples.\n",
      "\n",
      "Step 4: Combine the total number of oranges and apples Roger has now.  \n",
      "Total fruits = 5 oranges + 9 apples = 14 fruits.\n",
      "\n",
      "Final Answer: Roger has 5 oranges and 9 apples.\n"
     ]
    }
   ],
   "source": [
    "#perfect\n",
    "#now we want to try out zero shot COT prompting\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "    {\"role\":\"assistant\", \"content\":\"you are math expert. show step by step reasoning when giving the answer. use clear logic.dont explain each step when sollving each step.dont use special formatting like \\text{} or \\]\"},\n",
    "    \n",
    "    {\"role\":\"user\", \"content\":\n",
    "     \"Q:Roger has 2 packs of oranges each with 4, he gave 3 oranges of them to his friends and his friend gave roger 3 packs of apples each with 3.how many oranges and apples roger has?\\\n",
    "     A:lets think step by step\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "70c1fd48-1994-4e4e-b464-d5a049418cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "/tmp/ipykernel_1819/3214856530.py:4: SyntaxWarning: invalid escape sequence '\\['\n",
      "  {\"role\":\"assistant\", \"content\":\"you are math expert. show step by step reasoning when giving answer. use clear logic. not too much explanation. dont use special format like \\[ or \\text{}\"},\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When you were 6, your sister was half your age, which means she was 3 years old (6 / 2 = 3).\n",
      "\n",
      "The age difference between you and your sister is 3 years (6 - 3 = 3).\n",
      "\n",
      "Now that you are 16, your sister is 16 - 3 = 13 years old. \n",
      "\n",
      "So, your sister is 13 years old now.\n"
     ]
    }
   ],
   "source": [
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are math expert. show step by step reasoning when giving answer. use clear logic. not too much explanation. dont use special format like \\[ or \\text{}\"},\n",
    "        {\"role\":\"user\", \"content\":\"when I was 6 my sister was half of me , now I am 16 . how old is my sister?\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3dc5ea4a-dac0-4856-adfe-79b1bb1c165e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<quotes>Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize. She was the only person to win in two scientific fields.</quotes>\n"
     ]
    }
   ],
   "source": [
    "#prompt chaining\n",
    "\n",
    "# now it is turn to practice for prompt chaining\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are a helpful assistant.your task is answering the questions from the given document. \\\n",
    "        then output using <quotes></quotes>. Respond with 'No response found' if no relevant quotes were found. \"},\n",
    "        \n",
    "        \n",
    "        {\"role\":\"user\",\"content\":\"what was mary kury achievement.document:Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity. She was the first woman to win a Nobel Prize.\\\n",
    "        She was the only person to win in two scientific fields.\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "706dcf70-46b5-4c21-9d09-f93aeed13fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<quote>Marie Curie was the first woman to win a Nobel Prize and the only person to win in two scientific fields.</quote>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Marie Curie\\'s achievements include being \"the first woman to win a Nobel Prize and the only person to win in two scientific fields.\" She conducted pioneering research on radioactivity, making significant contributions to physics and chemistry.'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt chaining\n",
    "documents = \"\"\"\n",
    "            Marie Curie was a physicist and chemist who conducted pioneering research on radioactivity.\n",
    "            She was the first woman to win a Nobel Prize. She was the only person to win in two scientific fields.\n",
    "\n",
    "            \"\"\"\n",
    "question = \"what was Mary Cury achievment?\"\n",
    "quotes = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\":\"assistant\", \"content\":\"you are helpful assistant.you are responsible to extract relevant answer from the given document and wrap them in <quote>...</quote> if nothing is relevant respond no relvant information found\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "        f\"\"\"document:{documents}\\\n",
    "        question:{question}\"\"\"\n",
    "        \n",
    "        }\n",
    "    ]\n",
    ")\n",
    "print(quotes.choices[0].message.content)\n",
    "\n",
    "response_2 = openai.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":\"assistant\", \"content\":\"you are helpful assistant extracting quote from document.use both quote and document to combine them and give back a concise answer\"},\n",
    "        {\"role\":\"user\", \"content\":\n",
    "         f\"\"\"document:{documents}\\\n",
    "         quote:{quotes}\n",
    "         question:{question}\"\"\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "response_2.choices[0].message.content\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b09a5906-8448-4f0e-a68e-1ac1b2e7df83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
